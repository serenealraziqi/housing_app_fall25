{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17724,"status":"ok","timestamp":1765944563067,"user":{"displayName":"Serene Alraziqi","userId":"09274756293903734484"},"user_tz":300},"id":"dSDK_7Dj3YH9","outputId":"ad246a40-9fa7-4999-d78b-41f97201c010"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n","/content/drive/MyDrive/housing_app_fall25\n"]}],"source":["from google.colab import drive\n","from pathlib import Path\n","drive.mount(\"/content/drive\")\n","BASE = Path(\"/content/drive/MyDrive/housing_app_fall25\")\n","%cd \"{BASE}\"\n"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5275,"status":"ok","timestamp":1765944571684,"user":{"displayName":"Serene Alraziqi","userId":"09274756293903734484"},"user_tz":300},"id":"quIhilm65orD","outputId":"07fc14d8-ab73-4045-ec38-b60ab8dffbfd"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: xgboost in /usr/local/lib/python3.12/dist-packages (3.1.2)\n","Requirement already satisfied: lightgbm in /usr/local/lib/python3.12/dist-packages (4.6.0)\n","Requirement already satisfied: mlflow\u003c3 in /usr/local/lib/python3.12/dist-packages (2.22.4)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from xgboost) (2.0.2)\n","Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.12/dist-packages (from xgboost) (2.28.9)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from xgboost) (1.16.3)\n","Requirement already satisfied: mlflow-skinny==2.22.4 in /usr/local/lib/python3.12/dist-packages (from mlflow\u003c3) (2.22.4)\n","Requirement already satisfied: Flask\u003c4 in /usr/local/lib/python3.12/dist-packages (from mlflow\u003c3) (3.1.2)\n","Requirement already satisfied: Jinja2\u003c4,\u003e=2.11 in /usr/local/lib/python3.12/dist-packages (from mlflow\u003c3) (3.1.6)\n","Requirement already satisfied: alembic!=1.10.0,\u003c2 in /usr/local/lib/python3.12/dist-packages (from mlflow\u003c3) (1.17.2)\n","Requirement already satisfied: docker\u003c8,\u003e=4.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow\u003c3) (7.1.0)\n","Requirement already satisfied: graphene\u003c4 in /usr/local/lib/python3.12/dist-packages (from mlflow\u003c3) (3.4.3)\n","Requirement already satisfied: gunicorn\u003c24 in /usr/local/lib/python3.12/dist-packages (from mlflow\u003c3) (23.0.0)\n","Requirement already satisfied: markdown\u003c4,\u003e=3.3 in /usr/local/lib/python3.12/dist-packages (from mlflow\u003c3) (3.10)\n","Requirement already satisfied: matplotlib\u003c4 in /usr/local/lib/python3.12/dist-packages (from mlflow\u003c3) (3.10.0)\n","Requirement already satisfied: pandas!=2.3.0,\u003c3 in /usr/local/lib/python3.12/dist-packages (from mlflow\u003c3) (2.2.2)\n","Requirement already satisfied: pyarrow\u003c20,\u003e=4.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow\u003c3) (18.1.0)\n","Requirement already satisfied: scikit-learn\u003c2 in /usr/local/lib/python3.12/dist-packages (from mlflow\u003c3) (1.6.1)\n","Requirement already satisfied: sqlalchemy\u003c3,\u003e=1.4.0 in /usr/local/lib/python3.12/dist-packages (from mlflow\u003c3) (2.0.44)\n","Requirement already satisfied: cachetools\u003c6,\u003e=5.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==2.22.4-\u003emlflow\u003c3) (5.5.2)\n","Requirement already satisfied: click\u003c9,\u003e=7.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==2.22.4-\u003emlflow\u003c3) (8.3.1)\n","Requirement already satisfied: cloudpickle\u003c4 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==2.22.4-\u003emlflow\u003c3) (3.1.2)\n","Requirement already satisfied: databricks-sdk\u003c1,\u003e=0.20.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==2.22.4-\u003emlflow\u003c3) (0.74.0)\n","Requirement already satisfied: fastapi\u003c1 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==2.22.4-\u003emlflow\u003c3) (0.118.3)\n","Requirement already satisfied: gitpython\u003c4,\u003e=3.1.9 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==2.22.4-\u003emlflow\u003c3) (3.1.45)\n","Requirement already satisfied: importlib_metadata!=4.7.0,\u003c9,\u003e=3.7.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==2.22.4-\u003emlflow\u003c3) (8.7.0)\n","Requirement already satisfied: opentelemetry-api\u003c3,\u003e=1.9.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==2.22.4-\u003emlflow\u003c3) (1.37.0)\n","Requirement already satisfied: opentelemetry-sdk\u003c3,\u003e=1.9.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==2.22.4-\u003emlflow\u003c3) (1.37.0)\n","Requirement already satisfied: packaging\u003c25 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==2.22.4-\u003emlflow\u003c3) (24.2)\n","Requirement already satisfied: protobuf\u003c7,\u003e=3.12.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==2.22.4-\u003emlflow\u003c3) (5.29.5)\n","Requirement already satisfied: pydantic\u003c3,\u003e=1.10.8 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==2.22.4-\u003emlflow\u003c3) (2.12.3)\n","Requirement already satisfied: pyyaml\u003c7,\u003e=5.1 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==2.22.4-\u003emlflow\u003c3) (6.0.3)\n","Requirement already satisfied: requests\u003c3,\u003e=2.17.3 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==2.22.4-\u003emlflow\u003c3) (2.32.4)\n","Requirement already satisfied: sqlparse\u003c1,\u003e=0.4.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==2.22.4-\u003emlflow\u003c3) (0.5.4)\n","Requirement already satisfied: typing-extensions\u003c5,\u003e=4.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==2.22.4-\u003emlflow\u003c3) (4.15.0)\n","Requirement already satisfied: uvicorn\u003c1 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==2.22.4-\u003emlflow\u003c3) (0.38.0)\n","Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic!=1.10.0,\u003c2-\u003emlflow\u003c3) (1.3.10)\n","Requirement already satisfied: urllib3\u003e=1.26.0 in /usr/local/lib/python3.12/dist-packages (from docker\u003c8,\u003e=4.0.0-\u003emlflow\u003c3) (2.5.0)\n","Requirement already satisfied: blinker\u003e=1.9.0 in /usr/local/lib/python3.12/dist-packages (from Flask\u003c4-\u003emlflow\u003c3) (1.9.0)\n","Requirement already satisfied: itsdangerous\u003e=2.2.0 in /usr/local/lib/python3.12/dist-packages (from Flask\u003c4-\u003emlflow\u003c3) (2.2.0)\n","Requirement already satisfied: markupsafe\u003e=2.1.1 in /usr/local/lib/python3.12/dist-packages (from Flask\u003c4-\u003emlflow\u003c3) (3.0.3)\n","Requirement already satisfied: werkzeug\u003e=3.1.0 in /usr/local/lib/python3.12/dist-packages (from Flask\u003c4-\u003emlflow\u003c3) (3.1.4)\n","Requirement already satisfied: graphql-core\u003c3.3,\u003e=3.1 in /usr/local/lib/python3.12/dist-packages (from graphene\u003c4-\u003emlflow\u003c3) (3.2.7)\n","Requirement already satisfied: graphql-relay\u003c3.3,\u003e=3.1 in /usr/local/lib/python3.12/dist-packages (from graphene\u003c4-\u003emlflow\u003c3) (3.2.0)\n","Requirement already satisfied: python-dateutil\u003c3,\u003e=2.7.0 in /usr/local/lib/python3.12/dist-packages (from graphene\u003c4-\u003emlflow\u003c3) (2.9.0.post0)\n","Requirement already satisfied: contourpy\u003e=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib\u003c4-\u003emlflow\u003c3) (1.3.3)\n","Requirement already satisfied: cycler\u003e=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib\u003c4-\u003emlflow\u003c3) (0.12.1)\n","Requirement already satisfied: fonttools\u003e=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib\u003c4-\u003emlflow\u003c3) (4.61.0)\n","Requirement already satisfied: kiwisolver\u003e=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib\u003c4-\u003emlflow\u003c3) (1.4.9)\n","Requirement already satisfied: pillow\u003e=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib\u003c4-\u003emlflow\u003c3) (11.3.0)\n","Requirement already satisfied: pyparsing\u003e=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib\u003c4-\u003emlflow\u003c3) (3.2.5)\n","Requirement already satisfied: pytz\u003e=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas!=2.3.0,\u003c3-\u003emlflow\u003c3) (2025.2)\n","Requirement already satisfied: tzdata\u003e=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas!=2.3.0,\u003c3-\u003emlflow\u003c3) (2025.2)\n","Requirement already satisfied: joblib\u003e=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn\u003c2-\u003emlflow\u003c3) (1.5.2)\n","Requirement already satisfied: threadpoolctl\u003e=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn\u003c2-\u003emlflow\u003c3) (3.6.0)\n","Requirement already satisfied: greenlet\u003e=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy\u003c3,\u003e=1.4.0-\u003emlflow\u003c3) (3.3.0)\n","Requirement already satisfied: google-auth~=2.0 in /usr/local/lib/python3.12/dist-packages (from databricks-sdk\u003c1,\u003e=0.20.0-\u003emlflow-skinny==2.22.4-\u003emlflow\u003c3) (2.43.0)\n","Requirement already satisfied: starlette\u003c0.49.0,\u003e=0.40.0 in /usr/local/lib/python3.12/dist-packages (from fastapi\u003c1-\u003emlflow-skinny==2.22.4-\u003emlflow\u003c3) (0.48.0)\n","Requirement already satisfied: gitdb\u003c5,\u003e=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython\u003c4,\u003e=3.1.9-\u003emlflow-skinny==2.22.4-\u003emlflow\u003c3) (4.0.12)\n","Requirement already satisfied: zipp\u003e=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib_metadata!=4.7.0,\u003c9,\u003e=3.7.0-\u003emlflow-skinny==2.22.4-\u003emlflow\u003c3) (3.23.0)\n","Requirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk\u003c3,\u003e=1.9.0-\u003emlflow-skinny==2.22.4-\u003emlflow\u003c3) (0.58b0)\n","Requirement already satisfied: annotated-types\u003e=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic\u003c3,\u003e=1.10.8-\u003emlflow-skinny==2.22.4-\u003emlflow\u003c3) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic\u003c3,\u003e=1.10.8-\u003emlflow-skinny==2.22.4-\u003emlflow\u003c3) (2.41.4)\n","Requirement already satisfied: typing-inspection\u003e=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic\u003c3,\u003e=1.10.8-\u003emlflow-skinny==2.22.4-\u003emlflow\u003c3) (0.4.2)\n","Requirement already satisfied: six\u003e=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil\u003c3,\u003e=2.7.0-\u003egraphene\u003c4-\u003emlflow\u003c3) (1.17.0)\n","Requirement already satisfied: charset_normalizer\u003c4,\u003e=2 in /usr/local/lib/python3.12/dist-packages (from requests\u003c3,\u003e=2.17.3-\u003emlflow-skinny==2.22.4-\u003emlflow\u003c3) (3.4.4)\n","Requirement already satisfied: idna\u003c4,\u003e=2.5 in /usr/local/lib/python3.12/dist-packages (from requests\u003c3,\u003e=2.17.3-\u003emlflow-skinny==2.22.4-\u003emlflow\u003c3) (3.11)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests\u003c3,\u003e=2.17.3-\u003emlflow-skinny==2.22.4-\u003emlflow\u003c3) (2025.11.12)\n","Requirement already satisfied: h11\u003e=0.8 in /usr/local/lib/python3.12/dist-packages (from uvicorn\u003c1-\u003emlflow-skinny==2.22.4-\u003emlflow\u003c3) (0.16.0)\n","Requirement already satisfied: smmap\u003c6,\u003e=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb\u003c5,\u003e=4.0.1-\u003egitpython\u003c4,\u003e=3.1.9-\u003emlflow-skinny==2.22.4-\u003emlflow\u003c3) (5.0.2)\n","Requirement already satisfied: pyasn1-modules\u003e=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth~=2.0-\u003edatabricks-sdk\u003c1,\u003e=0.20.0-\u003emlflow-skinny==2.22.4-\u003emlflow\u003c3) (0.4.2)\n","Requirement already satisfied: rsa\u003c5,\u003e=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth~=2.0-\u003edatabricks-sdk\u003c1,\u003e=0.20.0-\u003emlflow-skinny==2.22.4-\u003emlflow\u003c3) (4.9.1)\n","Requirement already satisfied: anyio\u003c5,\u003e=3.6.2 in /usr/local/lib/python3.12/dist-packages (from starlette\u003c0.49.0,\u003e=0.40.0-\u003efastapi\u003c1-\u003emlflow-skinny==2.22.4-\u003emlflow\u003c3) (4.12.0)\n","Requirement already satisfied: pyasn1\u003c0.7.0,\u003e=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules\u003e=0.2.1-\u003egoogle-auth~=2.0-\u003edatabricks-sdk\u003c1,\u003e=0.20.0-\u003emlflow-skinny==2.22.4-\u003emlflow\u003c3) (0.6.1)\n"]}],"source":["!pip install xgboost lightgbm \"mlflow\u003c3\""]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":360},"executionInfo":{"elapsed":3414,"status":"ok","timestamp":1765944620058,"user":{"displayName":"Serene Alraziqi","userId":"09274756293903734484"},"user_tz":300},"id":"IRFqzWx-55CJ","outputId":"3e77f9b0-7712-45db-dc59-4e15e27347dd"},"outputs":[{"name":"stdout","output_type":"stream","text":["(7043, 6)\n","target\n","0    5174\n","1    1869\n","Name: count, dtype: int64\n"]},{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"summary":"{\n  \"name\": \"df\",\n  \"rows\": 7043,\n  \"fields\": [\n    {\n      \"column\": \"customer_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7043,\n        \"samples\": [\n          \"1024-GUALD\",\n          \"0484-JPBRU\",\n          \"3620-EHIMZ\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tenure\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 24.55948102309423,\n        \"min\": 0.0,\n        \"max\": 72.0,\n        \"num_unique_values\": 73,\n        \"samples\": [\n          8.0,\n          40.0,\n          12.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MonthlyCharges\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 30.09004709767854,\n        \"min\": 18.25,\n        \"max\": 118.75,\n        \"num_unique_values\": 1585,\n        \"samples\": [\n          48.85,\n          20.05,\n          36.85\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TotalCharges\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2266.7713618831453,\n        \"min\": 18.8,\n        \"max\": 8684.8,\n        \"num_unique_values\": 6530,\n        \"samples\": [\n          5594.0,\n          6840.95,\n          6148.45\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Contract\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Month-to-month\",\n          \"One year\",\n          \"Two year\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}","type":"dataframe","variable_name":"df"},"text/html":["\n","  \u003cdiv id=\"df-c468c244-55d9-44d3-aa15-9c6d1b06600a\" class=\"colab-df-container\"\u003e\n","    \u003cdiv\u003e\n","\u003cstyle scoped\u003e\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","\u003c/style\u003e\n","\u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n","    \u003ctr style=\"text-align: right;\"\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003ecustomer_id\u003c/th\u003e\n","      \u003cth\u003etenure\u003c/th\u003e\n","      \u003cth\u003eMonthlyCharges\u003c/th\u003e\n","      \u003cth\u003eTotalCharges\u003c/th\u003e\n","      \u003cth\u003eContract\u003c/th\u003e\n","      \u003cth\u003etarget\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003e7590-VHVEG\u003c/td\u003e\n","      \u003ctd\u003e1.0\u003c/td\u003e\n","      \u003ctd\u003e29.85\u003c/td\u003e\n","      \u003ctd\u003e29.85\u003c/td\u003e\n","      \u003ctd\u003eMonth-to-month\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e1\u003c/th\u003e\n","      \u003ctd\u003e5575-GNVDE\u003c/td\u003e\n","      \u003ctd\u003e34.0\u003c/td\u003e\n","      \u003ctd\u003e56.95\u003c/td\u003e\n","      \u003ctd\u003e1889.50\u003c/td\u003e\n","      \u003ctd\u003eOne year\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e2\u003c/th\u003e\n","      \u003ctd\u003e3668-QPYBK\u003c/td\u003e\n","      \u003ctd\u003e2.0\u003c/td\u003e\n","      \u003ctd\u003e53.85\u003c/td\u003e\n","      \u003ctd\u003e108.15\u003c/td\u003e\n","      \u003ctd\u003eMonth-to-month\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e3\u003c/th\u003e\n","      \u003ctd\u003e7795-CFOCW\u003c/td\u003e\n","      \u003ctd\u003e45.0\u003c/td\u003e\n","      \u003ctd\u003e42.30\u003c/td\u003e\n","      \u003ctd\u003e1840.75\u003c/td\u003e\n","      \u003ctd\u003eOne year\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e4\u003c/th\u003e\n","      \u003ctd\u003e9237-HQITU\u003c/td\u003e\n","      \u003ctd\u003e2.0\u003c/td\u003e\n","      \u003ctd\u003e70.70\u003c/td\u003e\n","      \u003ctd\u003e151.65\u003c/td\u003e\n","      \u003ctd\u003eMonth-to-month\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\n","\u003c/div\u003e\n","    \u003cdiv class=\"colab-df-buttons\"\u003e\n","\n","  \u003cdiv class=\"colab-df-container\"\u003e\n","    \u003cbutton class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c468c244-55d9-44d3-aa15-9c6d1b06600a')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\"\u003e\n","\n","  \u003csvg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\"\u003e\n","    \u003cpath d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/\u003e\n","  \u003c/svg\u003e\n","    \u003c/button\u003e\n","\n","  \u003cstyle\u003e\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  \u003c/style\u003e\n","\n","    \u003cscript\u003e\n","      const buttonEl =\n","        document.querySelector('#df-c468c244-55d9-44d3-aa15-9c6d1b06600a button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-c468c244-55d9-44d3-aa15-9c6d1b06600a');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '\u003ca target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb\u003edata table notebook\u003c/a\u003e'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    \u003c/script\u003e\n","  \u003c/div\u003e\n","\n","\n","    \u003cdiv id=\"df-14b50fc0-52ea-4c8f-b46d-9a5ed2848ec3\"\u003e\n","      \u003cbutton class=\"colab-df-quickchart\" onclick=\"quickchart('df-14b50fc0-52ea-4c8f-b46d-9a5ed2848ec3')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\"\u003e\n","\n","\u003csvg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\"\u003e\n","    \u003cg\u003e\n","        \u003cpath d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/\u003e\n","    \u003c/g\u003e\n","\u003c/svg\u003e\n","      \u003c/button\u003e\n","\n","\u003cstyle\u003e\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","\u003c/style\u003e\n","\n","      \u003cscript\u003e\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() =\u003e {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-14b50fc0-52ea-4c8f-b46d-9a5ed2848ec3 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      \u003c/script\u003e\n","    \u003c/div\u003e\n","\n","    \u003c/div\u003e\n","  \u003c/div\u003e\n"],"text/plain":["  customer_id  tenure  MonthlyCharges  TotalCharges        Contract  target\n","0  7590-VHVEG     1.0           29.85         29.85  Month-to-month       0\n","1  5575-GNVDE    34.0           56.95       1889.50        One year       0\n","2  3668-QPYBK     2.0           53.85        108.15  Month-to-month       1\n","3  7795-CFOCW    45.0           42.30       1840.75        One year       0\n","4  9237-HQITU     2.0           70.70        151.65  Month-to-month       1"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["import sqlite3\n","import pandas as pd\n","\n","conn = sqlite3.connect(\"telco.db\")  # created by notebook 01\n","\n","df = pd.read_sql_query(\"\"\"\n","SELECT s.customer_id,\n","       s.tenure, s.MonthlyCharges, s.TotalCharges,\n","       d.name AS Contract,\n","       s.target\n","FROM customer_stats s\n","JOIN customer c ON c.customer_id = s.customer_id\n","JOIN contract_dim d ON d.contract_id = c.contract_id;\n","\"\"\", conn)\n","\n","conn.close()\n","\n","print(df.shape)\n","print(df[\"target\"].value_counts())\n","df.head()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"m1pqkWQ53TFh"},"outputs":[{"name":"stderr","output_type":"stream","text":["2025/12/17 04:11:10 INFO mlflow.tracking.fluent: Experiment with name 'telco_churn_classification' does not exist. Creating a new experiment.\n","\u001b[31m2025/12/17 04:11:25 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n","\u001b[31m2025/12/17 04:11:32 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n","\u001b[31m2025/12/17 04:11:38 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n","\u001b[31m2025/12/17 04:11:44 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n","\u001b[31m2025/12/17 04:12:01 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n","\u001b[31m2025/12/17 04:12:26 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n","\u001b[31m2025/12/17 04:12:35 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n","\u001b[31m2025/12/17 04:12:42 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["BEST: xgb_standard\n","Test F1: 0.5545454545454546\n","CV F1 mean/std: 0.539788358984505 0.01208574920554894\n","Saved -\u003e models/model.joblib\n"]}],"source":["import os\n","import numpy as np\n","import mlflow\n","from sklearn.model_selection import train_test_split, cross_val_score\n","from sklearn.compose import ColumnTransformer\n","from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler, FunctionTransformer\n","from sklearn.pipeline import Pipeline\n","from sklearn.impute import SimpleImputer\n","from sklearn.metrics import f1_score, confusion_matrix\n","\n","from sklearn.linear_model import LogisticRegression, RidgeClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from xgboost import XGBClassifier\n","\n","# ---- basic cleanup ----\n","df[\"TotalCharges\"] = pd.to_numeric(df[\"TotalCharges\"], errors=\"coerce\")  # blanks -\u003e NaN\n","\n","X = df.drop(columns=[\"target\", \"customer_id\"])\n","y = df[\"target\"].astype(int)\n","\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y, test_size=0.2, random_state=42, stratify=y\n",")\n","\n","num_cols = [\"tenure\", \"MonthlyCharges\", \"TotalCharges\"]\n","cat_cols = [\"Contract\"]\n","\n","# log1p is your \"LogTransformation\"\n","log1p = FunctionTransformer(np.log1p, feature_names_out=\"one-to-one\")\n","\n","def make_pipeline(model, scaler=\"standard\"):\n","    scaler_obj = StandardScaler() if scaler == \"standard\" else MinMaxScaler()\n","\n","    num_pipe = Pipeline([\n","        (\"impute\", SimpleImputer(strategy=\"median\")),\n","        (\"log\", log1p),\n","        (\"scale\", scaler_obj),\n","    ])\n","\n","    pre = ColumnTransformer([\n","        (\"num\", num_pipe, num_cols),\n","        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n","    ])\n","\n","    return Pipeline([\n","        (\"preprocess\", pre),\n","        (\"model\", model),\n","    ])\n","\n","models = {\n","    # Experiment #1 baseline model\n","    \"logreg\": LogisticRegression(max_iter=600),\n","    # Experiment #2 models\n","    \"ridge\": RidgeClassifier(),\n","    \"rf\": RandomForestClassifier(n_estimators=300, random_state=42),\n","    \"xgb\": XGBClassifier(\n","        n_estimators=300, max_depth=4, learning_rate=0.1,\n","        subsample=0.9, colsample_bytree=0.9,\n","        eval_metric=\"logloss\", random_state=42\n","    ),\n","}\n","\n","mlflow.set_experiment(\"telco_churn_classification\")\n","\n","results = []\n","\n","for name, est in models.items():\n","    for scaler in [\"standard\", \"minmax\"]:\n","        run_name = f\"{name}_{scaler}\"\n","        pipe = make_pipeline(est, scaler=scaler)\n","\n","        # CV F1 (3-fold satisfies the rubric option)\n","        cv = cross_val_score(pipe, X_train, y_train, cv=3, scoring=\"f1\")\n","        cv_mean, cv_std = float(cv.mean()), float(cv.std())\n","\n","        pipe.fit(X_train, y_train)\n","        pred = pipe.predict(X_test)\n","\n","        f1 = float(f1_score(y_test, pred))\n","        tn, fp, fn, tp = confusion_matrix(y_test, pred).ravel()\n","\n","        with mlflow.start_run(run_name=run_name):\n","            mlflow.log_param(\"model\", name)\n","            mlflow.log_param(\"scaler\", scaler)\n","            mlflow.log_metric(\"cv_f1_mean\", cv_mean)\n","            mlflow.log_metric(\"cv_f1_std\", cv_std)\n","            mlflow.log_metric(\"test_f1\", f1)\n","            mlflow.log_metric(\"tn\", int(tn))\n","            mlflow.log_metric(\"fp\", int(fp))\n","            mlflow.log_metric(\"fn\", int(fn))\n","            mlflow.log_metric(\"tp\", int(tp))\n","            mlflow.sklearn.log_model(pipe, artifact_path=\"model\")\n","\n","        results.append((run_name, f1, cv_mean, cv_std, pipe))\n","\n","# choose best by TEST F1 (higher is better)\n","best = max(results, key=lambda x: x[1])\n","best_name, best_test_f1, best_cv_mean, best_cv_std, best_pipe = best\n","\n","print(\"BEST:\", best_name)\n","print(\"Test F1:\", best_test_f1)\n","print(\"CV F1 mean/std:\", best_cv_mean, best_cv_std)\n","\n","os.makedirs(\"models\", exist_ok=True)\n","import joblib\n","joblib.dump(best_pipe, \"models/model.joblib\")\n","print(\"Saved -\u003e models/model.joblib\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oIzkre56giUw"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RTqNkkbR33iG","outputId":"463058a0-4a86-4aa1-b191-dd24eb27442d"},"outputs":[{"name":"stdout","output_type":"stream","text":["✓ STEP 1: Preprocessing pipeline created.\n","✓ STEP 2: Stratified split done. Train size: 16512, Test size: 4128\n","✓ STEP 3: 4 baseline model pipelines defined.\n","✓ STEP 4: MLflow configured.\n","\n","================================================================================\n","Training baseline model: ridge\n","================================================================================\n","ridge (no PCA) CV MAE: $51,151.03\n","ridge (no PCA) Test MAE: $52,350.18\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.12/dist-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values \u003chttps://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values\u003e`_ for more details.\n","  warnings.warn(\n","Registered model 'ridge_pipeline' already exists. Creating a new version of this model...\n","Created version '5' of model 'ridge_pipeline'.\n"]},{"name":"stdout","output_type":"stream","text":["\n","================================================================================\n","Training baseline model: histgradientboosting\n","================================================================================\n","histgradientboosting (no PCA) CV MAE: $30,702.81\n","histgradientboosting (no PCA) Test MAE: $30,702.41\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.12/dist-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values \u003chttps://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values\u003e`_ for more details.\n","  warnings.warn(\n","Registered model 'histgradientboosting_pipeline' already exists. Creating a new version of this model...\n","Created version '5' of model 'histgradientboosting_pipeline'.\n"]},{"name":"stdout","output_type":"stream","text":["\n","================================================================================\n","Training baseline model: xgboost\n","================================================================================\n","xgboost (no PCA) CV MAE: $28,831.45\n","xgboost (no PCA) Test MAE: $28,465.49\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.12/dist-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values \u003chttps://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values\u003e`_ for more details.\n","  warnings.warn(\n","Registered model 'xgboost_pipeline' already exists. Creating a new version of this model...\n","Created version '5' of model 'xgboost_pipeline'.\n"]},{"name":"stdout","output_type":"stream","text":["\n","================================================================================\n","Training baseline model: lightgbm\n","================================================================================\n","lightgbm (no PCA) CV MAE: $29,422.96\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003784 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 4651\n","[LightGBM] [Info] Number of data points in the train set: 16512, number of used features: 23\n","[LightGBM] [Info] Start training from score 206333.518653\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["lightgbm (no PCA) Test MAE: $29,684.98\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values \u003chttps://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values\u003e`_ for more details.\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n","  warnings.warn(\n","Registered model 'lightgbm_pipeline' already exists. Creating a new version of this model...\n","Created version '5' of model 'lightgbm_pipeline'.\n"]},{"name":"stdout","output_type":"stream","text":["\n","✓ STEP 5: All 4 baseline models trained and logged.\n","\n","================================================================================\n","Training PCA-augmented model: ridge\n","================================================================================\n","ridge_with_pca CV MAE: $56,480.26\n","ridge_with_pca Test MAE: $56,738.52\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.12/dist-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values \u003chttps://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values\u003e`_ for more details.\n","  warnings.warn(\n","Registered model 'ridge_pipeline_with_pca' already exists. Creating a new version of this model...\n","Created version '4' of model 'ridge_pipeline_with_pca'.\n"]},{"name":"stdout","output_type":"stream","text":["\n","================================================================================\n","Training PCA-augmented model: histgradientboosting\n","================================================================================\n","histgradientboosting_with_pca CV MAE: $38,567.13\n","histgradientboosting_with_pca Test MAE: $37,990.38\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.12/dist-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values \u003chttps://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values\u003e`_ for more details.\n","  warnings.warn(\n","Registered model 'histgradientboosting_pipeline_with_pca' already exists. Creating a new version of this model...\n","Created version '4' of model 'histgradientboosting_pipeline_with_pca'.\n"]},{"name":"stdout","output_type":"stream","text":["\n","================================================================================\n","Training PCA-augmented model: xgboost\n","================================================================================\n","xgboost_with_pca CV MAE: $38,057.22\n","xgboost_with_pca Test MAE: $37,367.20\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.12/dist-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values \u003chttps://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values\u003e`_ for more details.\n","  warnings.warn(\n","Registered model 'xgboost_pipeline_with_pca' already exists. Creating a new version of this model...\n","Created version '4' of model 'xgboost_pipeline_with_pca'.\n"]},{"name":"stdout","output_type":"stream","text":["\n","================================================================================\n","Training PCA-augmented model: lightgbm\n","================================================================================\n","lightgbm_with_pca CV MAE: $37,690.64\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015235 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 2295\n","[LightGBM] [Info] Number of data points in the train set: 16512, number of used features: 9\n","[LightGBM] [Info] Start training from score 206333.518653\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["lightgbm_with_pca Test MAE: $37,631.80\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values \u003chttps://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values\u003e`_ for more details.\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n","  warnings.warn(\n","Registered model 'lightgbm_pipeline_with_pca' already exists. Creating a new version of this model...\n","Created version '4' of model 'lightgbm_pipeline_with_pca'.\n"]},{"name":"stdout","output_type":"stream","text":["\n","✓ STEP 7: All 4 PCA models trained and logged.\n","\n","================================================================================\n","GLOBAL BEST MODEL (ACROSS 8 CANDIDATES)\n","================================================================================\n","Global best model key: xgboost\n","Global best CV MAE:    $28,831.45\n","Global best Test MAE:  $28,465.49\n","Uses PCA:               False\n","\n","--------------------------------------------------------------------------------\n","Saving and reloading GLOBAL best model...\n","--------------------------------------------------------------------------------\n","✓ Model saved to /content/drive/MyDrive/Colab Notebooks/housing_fall2025/models/global_best_model.pkl\n","\n","Done:\n","- GLOBAL best model key: xgboost\n","- GLOBAL best CV MAE:    $28,831.45\n","- GLOBAL best Test MAE:  $28,465.49\n","Elapsed time: 2 minutes and 50.34 seconds\n"]}],"source":["# =============================================================================\n","# FULL PIPELINE:\n","# - Build preprocessing\n","# - Stratified train/test split\n","# - Train \u0026 log 4 models WITHOUT PCA (Ridge, HGB, XGBoost, LightGBM)\n","# - Train \u0026 log 4 models WITH PCA (preprocessing + PCA(0.95) + model)\n","# - Pick GLOBAL best among 8 models by Test MAE\n","# - Save, load, and compare the global best model\n","# =============================================================================\n","\n","import os\n","import numpy as np\n","import pandas as pd\n","import time\n","\n","from dotenv import load_dotenv\n","\n","from sklearn.decomposition import PCA\n","from sklearn.metrics import mean_absolute_error\n","from sklearn.model_selection import train_test_split, cross_val_score\n","from sklearn.pipeline import make_pipeline\n","\n","import mlflow\n","from mlflow.models import infer_signature\n","import joblib\n","\n","# Import shared components\n","from housing_pipeline import (\n","    build_preprocessing,\n","    make_estimator_for_name,\n",")\n","\n","start_time = time.monotonic()\n","\n","# =============================================================================\n","# STEP 1: Build Full ML Preprocessing Pipeline\n","# =============================================================================\n","\n","preprocessing = build_preprocessing()\n","print(\"✓ STEP 1: Preprocessing pipeline created.\")\n","\n","\n","# =============================================================================\n","# STEP 2: Split Data into Stratified Train and Test Sets\n","# =============================================================================\n","\n","housing[\"income_cat\"] = pd.cut(\n","    housing[\"median_income\"],\n","    bins=[0, 1.5, 3.0, 4.5, 6, np.inf],\n","    labels=[1, 2, 3, 4, 5],\n",")\n","\n","train_set, test_set = train_test_split(\n","    housing,\n","    test_size=0.20,\n","    stratify=housing[\"income_cat\"],\n","    random_state=42,\n",")\n","\n","for df in (train_set, test_set):\n","    df.drop(\"income_cat\", axis=1, inplace=True)\n","\n","X_train = train_set.drop([\"block_id\", \"median_house_value\"], axis=1).copy()\n","y_train = train_set[\"median_house_value\"].copy()\n","\n","X_test = test_set.drop([\"block_id\", \"median_house_value\"], axis=1).copy()\n","y_test = test_set[\"median_house_value\"].copy()\n","\n","print(f\"✓ STEP 2: Stratified split done. Train size: {len(X_train)}, Test size: {len(X_test)}\")\n","\n","\n","# =============================================================================\n","# STEP 3: Define 4 Model Pipelines (WITHOUT PCA)\n","# =============================================================================\n","\n","models = {}\n","for name in [\"ridge\", \"histgradientboosting\", \"xgboost\", \"lightgbm\"]:\n","    est = make_estimator_for_name(name)\n","    models[name] = make_pipeline(preprocessing, est)\n","\n","print(\"✓ STEP 3: 4 baseline model pipelines defined.\")\n","\n","\n","# =============================================================================\n","# STEP 4: Configure MLflow (e.g., Dagshub) via .env\n","# =============================================================================\n","\n","load_dotenv(\n","    dotenv_path=\"/content/gdrive/MyDrive/Colab Notebooks/housing_fall2025/notebooks/.env\",\n","    override=True\n",")\n","\n","MLFLOW_TRACKING_URI = os.getenv(\"MLFLOW_TRACKING_URI\")\n","MLFLOW_TRACKING_USERNAME = os.getenv(\"MLFLOW_TRACKING_USERNAME\")\n","MLFLOW_TRACKING_PASSWORD = os.getenv(\"MLFLOW_TRACKING_PASSWORD\")\n","\n","if MLFLOW_TRACKING_USERNAME:\n","    os.environ[\"MLFLOW_TRACKING_USERNAME\"] = MLFLOW_TRACKING_USERNAME\n","if MLFLOW_TRACKING_PASSWORD:\n","    os.environ[\"MLFLOW_TRACKING_PASSWORD\"] = MLFLOW_TRACKING_PASSWORD\n","\n","mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n","mlflow.set_experiment(\"median_house_pricing_multi_model\")\n","\n","print(\"✓ STEP 4: MLflow configured.\")\n","\n","\n","# =============================================================================\n","# STEP 5: Train, Evaluate, and Log 4 Baseline Models (NO PCA)\n","# =============================================================================\n","\n","results = {}\n","\n","for name, pipeline in models.items():\n","    print(f\"\\n{'=' * 80}\")\n","    print(f\"Training baseline model: {name}\")\n","    print(f\"{'=' * 80}\")\n","\n","    # Compute CV MAE before fitting on full training set\n","    cv_scores = cross_val_score(\n","        pipeline, X_train, y_train,\n","        cv=3, scoring=\"neg_mean_absolute_error\", n_jobs=-1\n","    )\n","    cv_mae = -cv_scores.mean()\n","    print(f\"{name} (no PCA) CV MAE: ${cv_mae:,.2f}\")\n","\n","    # Fit on full training set\n","    pipeline.fit(X_train, y_train)\n","\n","    # Evaluate on test set\n","    y_pred = pipeline.predict(X_test)\n","    test_mae = mean_absolute_error(y_test, y_pred)\n","    print(f\"{name} (no PCA) Test MAE: ${test_mae:,.2f}\")\n","\n","    results[name] = {\"pipeline\": pipeline, \"test_mae\": test_mae, \"cv_mae\": cv_mae}\n","\n","    with mlflow.start_run(run_name=f\"{name}_baseline\"):\n","        mlflow.log_param(\"model_family\", name)\n","        mlflow.log_param(\"uses_pca\", False)\n","\n","        est_step_name = list(pipeline.named_steps.keys())[-1]\n","        est = pipeline.named_steps[est_step_name]\n","        est_params = {f\"{est_step_name}__{k}\": v for k, v in est.get_params().items()}\n","        mlflow.log_params(est_params)\n","\n","        mlflow.log_metric(\"cv_MAE\", cv_mae)\n","        mlflow.log_metric(\"test_MAE\", test_mae)\n","\n","        signature = infer_signature(X_train, pipeline.predict(X_train))\n","        mlflow.sklearn.log_model(\n","            sk_model=pipeline,\n","            artifact_path=\"housing_model\",\n","            signature=signature,\n","            input_example=X_train,\n","            registered_model_name=f\"{name}_pipeline\",\n","        )\n","\n","print(\"\\n✓ STEP 5: All 4 baseline models trained and logged.\")\n","\n","\n","# =============================================================================\n","# STEP 7: Train, Evaluate, and Log PCA Versions of ALL 4 Models\n","# =============================================================================\n","\n","pca_results = {}\n","\n","for name in models.keys():\n","    print(\"\\n\" + \"=\" * 80)\n","    print(f\"Training PCA-augmented model: {name}\")\n","    print(\"=\" * 80)\n","\n","    est = make_estimator_for_name(name)\n","\n","    pca_pipeline = make_pipeline(\n","        preprocessing,\n","        PCA(n_components=0.95),\n","        est,\n","    )\n","\n","    # Compute CV MAE before fitting on full training set\n","    cv_scores_pca = cross_val_score(\n","        pca_pipeline, X_train, y_train,\n","        cv=3, scoring=\"neg_mean_absolute_error\", n_jobs=-1\n","    )\n","    cv_mae_pca = -cv_scores_pca.mean()\n","    print(f\"{name}_with_pca CV MAE: ${cv_mae_pca:,.2f}\")\n","\n","    # Fit on full training set\n","    pca_pipeline.fit(X_train, y_train)\n","\n","    # Evaluate on test set\n","    y_pred_pca = pca_pipeline.predict(X_test)\n","    test_mae_pca = mean_absolute_error(y_test, y_pred_pca)\n","\n","    model_key = f\"{name}_with_pca\"\n","    pca_results[model_key] = {\n","        \"pipeline\": pca_pipeline,\n","        \"test_mae\": test_mae_pca,\n","        \"cv_mae\": cv_mae_pca,\n","    }\n","\n","    print(f\"{model_key} Test MAE: ${test_mae_pca:,.2f}\")\n","\n","    with mlflow.start_run(run_name=model_key):\n","        mlflow.log_param(\"model_family\", name)\n","        mlflow.log_param(\"uses_pca\", True)\n","\n","        est_step_name = list(pca_pipeline.named_steps.keys())[-1]\n","        est_step = pca_pipeline.named_steps[est_step_name]\n","        est_params = {f\"{est_step_name}__{k}\": v for k, v in est_step.get_params().items()}\n","        mlflow.log_params(est_params)\n","\n","        pca_step = pca_pipeline.named_steps[\"pca\"]\n","        mlflow.log_param(\"pca__n_components\", pca_step.n_components)\n","\n","        mlflow.log_metric(\"cv_MAE\", cv_mae_pca)\n","        mlflow.log_metric(\"test_MAE\", test_mae_pca)\n","\n","        signature_pca = infer_signature(X_train, pca_pipeline.predict(X_train))\n","        mlflow.sklearn.log_model(\n","            sk_model=pca_pipeline,\n","            artifact_path=\"housing_model_with_pca\",\n","            signature=signature_pca,\n","            input_example=X_train,\n","            registered_model_name=f\"{name}_pipeline_with_pca\",\n","        )\n","\n","print(\"\\n✓ STEP 7: All 4 PCA models trained and logged.\")\n","\n","\n","# =============================================================================\n","# STEP 8: Choose GLOBAL Best Model (with or without PCA)\n","# =============================================================================\n","\n","all_results = {}\n","all_results.update(results)\n","all_results.update(pca_results)\n","\n","global_best_name = min(all_results, key=lambda k: all_results[k][\"test_mae\"])\n","global_best_mae = all_results[global_best_name][\"test_mae\"]\n","global_best_cv_mae = all_results[global_best_name][\"cv_mae\"]\n","global_best_pipeline = all_results[global_best_name][\"pipeline\"]\n","\n","uses_pca = \"with_pca\" in global_best_name\n","\n","print(\"\\n\" + \"=\" * 80)\n","print(\"GLOBAL BEST MODEL (ACROSS 8 CANDIDATES)\")\n","print(\"=\" * 80)\n","print(f\"Global best model key: {global_best_name}\")\n","print(f\"Global best CV MAE:    ${global_best_cv_mae:,.2f}\")\n","print(f\"Global best Test MAE:  ${global_best_mae:,.2f}\")\n","print(f\"Uses PCA:               {uses_pca}\")\n","\n","\n","# =============================================================================\n","# STEP 9: Save, Load, and Compare the GLOBAL Best Model\n","# =============================================================================\n","\n","def save_model(model, filename=\"global_best_model.pkl\"):\n","    joblib.dump(model, filename)\n","    print(f\"✓ Model saved to {filename}\")\n","\n","print(\"\\n\" + \"-\" * 80)\n","print(\"Saving and reloading GLOBAL best model...\")\n","print(\"-\" * 80)\n","\n","save_model(global_best_pipeline, filename=f\"{base_folder}/models/global_best_model.pkl\")\n","\n","print(\"\\nDone:\")\n","print(f\"- GLOBAL best model key: {global_best_name}\")\n","print(f\"- GLOBAL best CV MAE:    ${global_best_cv_mae:,.2f}\")\n","print(f\"- GLOBAL best Test MAE:  ${global_best_mae:,.2f}\")\n","\n","end_time = time.monotonic()\n","elapsed_time = end_time - start_time\n","minutes = int(elapsed_time // 60)\n","seconds = elapsed_time % 60\n","print(f\"Elapsed time: {minutes} minutes and {seconds:.2f} seconds\")"]}],"metadata":{"colab":{"name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}